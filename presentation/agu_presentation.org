#+TITLE: Using Neural Networks for Bayesian Precipitation @@latex: \\ @@ Retrievals
#+SUBTITLE: from GPM Passive Microwave Observations
#+AUTHOR: @@latex: \textbf{Simon Pfreunschuh}$^{1}$\\[0.1cm]@@ Teodor Norrestad @@latex: $^{2}$\\[0.05cm]@@  Patrick Eriksson @@latex: $^1$\\[0.05cm]@@ Inderpreet Kaur @@latex: $^{1}$\\[0.05cm] @@ Christian D. Kummerow @@latex: $^{3}$\\[0.05cm]@@
#+EMAIL: simon.pfreundschuh@chalmers.se
#+OPTIONS: H:2 toc:nil
#+LaTeX_CLASS_OPTIONS: [9pt]
#+LaTeX_HEADER: \institute{$^{1}$ Chalmers University of Technology \\ $^{2}$ previously Chalmers University of Technology \\ $^{3}$ Colorado State University}
#+LaTeX_HEADER: \usepackage{natbib}
#+LaTeX_HEADER: \usepackage{siunitx}
#+LaTeX_HEADER: \usepackage{subcaption}
#+LaTeX_HEADER: \usepackage{todonotes}
#+LaTeX_HEADER: \usepackage{units}
#+LATEX_HEADER: \usepackage{dirtree}
#+LaTeX_HEADER: \usetheme{chalmers}
#+LATEX_HEADER: \newcommand\blfootnote[1]{\begingroup \renewcommand\thefootnote{}\footnote{#1} \addtocounter{footnote}{-1} \endgroup}
#+LaTeX_HEADER: \setbeamerfont{title}{size=\LARGE}

* Outline

* Background: GPM and GPROF
** Background: GPM and GPROF
   - \textbf{Global Precipitation Measurement (GPM)}: Constellation of microwave
    radiometers providing frequent ($T \leq 3 \unit{h}$) global measurements of precipitation

   - \textbf{Goddard Profiling Algorithm (GPROF)}:  The retrieval algorithm used to retrieve
     precipitation profiles.

  \blfootnote{Image source: NASA}

   \centering
  \includegraphics[width=0.65\textwidth]{figures/gpm_constellation}

** Outline
 \begin{alertblock}{Research question:}   
    \textbf{Can we use a neural-network-based retrieval in the next version of GPROF?}
 \end{alertblock}
 \vspace{1cm}
*** Motivation
   - Simpler and faster
   - Greater flexibility with respect to input variables
   - Better retrievals

*** This study
    - Developed a neural-network-based surface precipitation retrieval 
    - 1-to-1 comparison to the current GPROF version

*** References, code, and models
    - Check out the project page: https://github.com/see-mof/regn

** GPROF Version 5

- Bayesian retrieval method: Monte Carlo Integration (MCI)
- Posterior approximated using importance sampling based deviation from obs.
- A priori databases stratified by surface type,  two-meter temperature, total column water vapor

 \vspace{0.5cm}
  
  \centering
  \includegraphics[width=0.8\textwidth]{figures/mci_2}


** Quantile regression neural network (QRNN)

   - Trained to minimize quantile loss function (skewed absolute error):
     \begin{align}
     \mathcal{L}(x_\tau, x) = \begin{cases}
          \tau |x_\tau - x| & x_\tau \leq x \\
          (1 - \tau) |x_\tau - x| & \text{otherwise}
          \end{cases}
     \end{align}


 \vspace{0.5cm}
  
  \centering
  \includegraphics[width=1.0\textwidth]{figures/qrnn}

** Quantile regression neural network (QRNN)
*** A block                                           :B_ignoreheading:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.4
    :END:

**** Predicted posterior
     \vspace{1cm}
    \includegraphics[width=\textwidth]{figures/cdf}

*** A screenshot                                            :BMCOL:B_example:
    :PROPERTIES:
    :BEAMER_col: 0.6
    :END:

**** Derived statistics

  - Point predictors:
    - Median: $x_{\tau=.5}$
    - Posterior mean: $\mathbf{E}(x|y) = \int x\: dF$
  - Confidence intervals:
    \begin{align*}
    P(x_{\tau=.45} < X \leq x_{\tau=.55}) &= 10\% \\
    P(x_{\tau=.35} < X \leq x_{\tau=.65}) &= 30\% \\
    \ldots &
      \end{align*}
  - Classifier:
    \begin{align*}
    P(X > x) = 1 - F(x)
    \end{align*}

** Our Experiment

*** Can QRNN replace Monte-Carlo integration?
*** A block                                           :B_ignoreheading:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.6
    :END:
**** Training
    - Data: GPROF V5 a-priori database (GMI/DPR combined observations)
    - QRNN: Fully-connected NN, 10 layers, 128 neurons, ReLU activations

**** Evaluation
    - Day 1 and 2 of each month left out for testing
    - Real GMI observations matched to nearest sample in retrieval database
    - Data subsampled to decrease redundancy

*** A block                                           :B_ignoreheading:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.45
    :END:
    \includegraphics[width=\textwidth]{figures/colocations}


** Accuracy of point estimates
    - Reduced bias in QRNN results
    - Minor reductions in MSE and MAE

**** Deviations for rain rates  $> 0.3\:\unit{mm\ h{^{-1}}}$:
   \includegraphics[width=0.9\textwidth]{figures/error_distributions}

** Accuracy of point estimates
    - Reductions mostly consistent across surface types

   \includegraphics[width=\textwidth]{figures/error_summary}


** Calibration of uncertainty estimates
*** A block                                           :B_ignoreheading:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:

     - Predicted confidence intervals consistent with observed deviations
     - Not the case for GPROF 1st and 3rd precipitation terciles

*** A block                                           :B_ignoreheading:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
   \includegraphics[width=\textwidth]{figures/calibration}

** Classification accuracy

*** A block                                           :B_ignoreheading:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
**** Receiver operating characteristic
     - Raining/Non-raining classification, threshold = $0.01\ \unit{mm\ h^{-1}}$
     - QRNN predictions more reliable than GPROF probability of precipitation

*** A block                                           :B_ignoreheading:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
   \includegraphics[width=\textwidth]{figures/roc}

** Validation against ground radar
*** GMI
    
   \includegraphics[width=\textwidth]{figures/colocations_gmi}


** Validation against ground radar
*** MHS
    - QRNN works equally well for cross-track scanning sensor
    - One network can handle all viewing angles

   \includegraphics[width=\textwidth]{figures/colocations_mhs}

** Conclusions
*** Can QRNNs replace Monte Carlo integration?
    - Results, so far, indicate yes

*** Potential improvements
    1. More accurate point estimates
    2. Better estimate of the posterior distribution (uncertainty, classification)
    3. One network can handle different surface types and viewing angles
    4. Potential path towards making use of spatial information


** Future work
*** Next steps
    - Run QRNN-based GPROF version in parallel with MCI-based version
    - Evaluate QRNN-based GPROF in production

*** Open questions
    - Profile retrievals
    - Correlated errors

*** More information, code and models
    - Check out the project page: https://github.com/see-mof/regn
